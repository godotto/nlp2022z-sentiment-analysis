\newpage
\section{Metody analizy sentymentów}
\subsection{Rodzaje zadań}
Podstawowym i najpowszechniejszym zadaniem w ramach analizy wydźwięku jest wykrywanie emocji, jakie niesie ze sobą dany dokument lub zdanie -- pozytywnych lub negatywnych, rzadziej neutralnych. Ten rodzaj
zadań jest tematem niniejszego projektu.
Innymi powszechnymi zadaniami jest klasyfikacja tekstów jako subiektywne lub obiektywne oraz
ocena dokumentów jako istotne bądź nieistotne względem danego tematu.

Powyższe zagadnienia są problemami dychotomicznymi, nie licząc wariantu wykrywania emocji
z uwzględnieniem neutralnych wypowiedzi, ale wieloklasowe problemy również mogą należeć
do kręgu wykrywania wydźwięku. Modele wieloklasowe mogą oceniać między innymi to, jakiej
kwestii dotyczy dany dokument.

\subsection{Wykorzystywane techniki}
\subsubsection{Metody bazujące na wiedzy}
Do wykrywania wydźwięku można podejść metodami bazującymi na wiedzy oraz metodami statystycznymi (uczenie maszynowe).
Te pierwsze wykorzystują wcześniej zdobytą wiedzę na temat znaczenia i wydźwięku danych słów.
Obecność jednoznacznie nacechowanych słów przeważa za nadaniem dokumentowi odpowiedniej
kategorii, na przykład obecność słów „zły” i „zdenerwowany” wskazuje na potencjalny
negatywny wydźwięk tekstu.

\subsubsection{Uczenie maszynowe}
Metody uczenia maszynowego z kolei analizują teksty, którym zostały wcześniej przypisane etykiety
z danymi emocjami, a następnie na bazie wyuczonych wzorców dokonują predykcji wskazując
klasę podanych do modelu danych. Są do tego wykorzystywane zarówno klasyczne metody
uczenia z nadzorem takie jak maszyny wektorów nośnych, losowy las decyzyjny i naiwny 
klasyfikator Bayesa, ale także sieci neuronowe, między innymi sieci rekurencyjne,
perceptrony wielowarstwowe, czy nawet używane głównie do przetwarzania obrazów splotowe
sieci neuronowe \cite{kim2014}.

Uczenie maszynowe wymaga, aby dane były reprezentowane w sposób numeryczny. Dane można 
reprezentować na przykład za pomocą bag-of-words - multizbioru słów, zawierającego jedynie
statystykę wystąpień słów, ale także za pomocą word embeddings, czyli osadzeń słów w wektory.
Metody word embedding pozwalają na zapisanie znaczeń słów -- dwa słowa są tym bliższe sobie,
im bliżej są ich wektory w przestrzeni liniowej. Powszechnie stosuje się wcześniej wytrenowane
modele word embeddingu takie jak word2vec\cite{word2vec}, GloVe\cite{glove} czy fastText\cite{fasttext-vectors}.

Jeszcze bardziej zaawansowane metody próbują analizować kontekst czy podmiot w danej wypowiedzi
na podstawie analiz gramatycznych.

Z kolei najnowszym osiągnięciem w dziedzinie są architektury transformatowe\cite{transformers}. Są skonstruowane
w sposób podobny do sieci rekurencyjnych, ale w przeciwieństwie do nich przetwarzają wszystkie
dane wejściowe na raz oraz wykorzystują mechanizm atencji. Do takich modeli należą BERT\cite{bert} czy
GPT\cite{gpt}. Te modele mogą służyć w wielu problemach związanych z przetwarzaniem języka naturalnego,
włącznie z analizą wydźwięku. Mogą być również zastosowane jako warstwa emebddingu do innych
architektur, zamiast dedykowanych temu modeli jak wspomniane wcześniej embeddery.

\subsubsection{Metody hybrydowe}
Modele uczenia maszynowego mogą być wspierane przez metody oparte na wiedzy. Wiedza może
pochodzić na przykład z ontologii oraz z sieci semantycznych.

\subsection{Przykłady istniejących architektur}
Jedną z najbardziej znanych architektur sieci neuronowych do klasyfikacji tekstu
jest fastText\cite{fasttext-classification}. Została stworzona przez zespół badawczy Facebooka, następnie projekt wyewoluował
w bibliotekę zawierającą także narzędzia do word embeddingów. Jest to płytka sieć neuronowa.
Składa się jedynie z warstwy embeddingowej, warstwy gęstej (ukrytej) oraz warstwy wyjściowej
zakończonej funkcją softmax. Zdecydowaną zaletą tej architektury jest jej szybkość. Jest
w stanie osiągnąć dokładność architektur opartych na sieciach rekurencyjnych przy znacznie
krótszym czasie treningu.

Nieco mniej konwencjonalną metodą analizy wydźwięku jest stosowanie splotowych
sieci neuronowych (CNN). Yoon Kim w swojej pracy „Convolutional Neural Networks for Sentence 
Classification”\cite{cnn} porównał proste modele oparte na sieci złożonej z warstwy embeddingowej,
z wektorami uzyskanymi z word2vec, jednej warstwy splotu oraz wyjściowej warstwy
gęstej zakończonej softmaxem. Modele stworzone przez autora artykułu w większości
przypadków miały przewagę nad innymi modelami. Ponadto została przez niego podkreślona istotność
wykorzystania wyuczonych wcześniej word embeddingów -- wariant CNN pozbawiony word2vec
radził sobie najgorzej.
