\newpage
\section{Projekt implementacji}
\subsection{Skrypt do pozyskiwania danych z serwisu Amazon}
Przed przystąpieniem do trenowania modeli analizy wydźwięku należy zebrać odpowiednio liczny zbiór danych, które posłużą za dane testowe i treningowe dla implementowanego algorytmu.

Ze względu na fakt, że istnieje wiele narzędzi pomagających w pobieraniu wpisów zintegrowanych z tym portalem, a także na łatwość przekładania liczby gwiazdek przyznanych produktowi przez użytkownika na wydźwięk pozytywny, negatywny bądź neutralny, zdecydowano się trenować model na danych pochodzących z amerykańskiej wersji sklepu internetowego Amazon.

Wybrano po kilka-kilkanaście produktów ze zadanych trzech kategorii i wyszukano je w serwisie Amazon. Następnie ich strony główne, zawierające recenzje stanowiące docelowy zestaw danych, pobrano w formie pliku HTML. W tym celu wykorzystano interfejs \textbf{ScraperAPI}\cite{scraperapi}, obsługujący serwery proxy, przeglądarki oraz CAPTCHA i tym samym pozwalający na uzyskanie HTML z dowolnej strony internetowej o znanym adresie URL za pomocą prostego wywołania w dowolnym języku. Zastosowanie takiego interfejsu lub innego, równoważnego narzędzia jest kluczowe w przypadku pobierania danych z serwisu, który implementuje zabezpieczenia przeciwko botom - inaczej żądania są blokowane.

Narzędzie, które zostało wykorzystane w celu wydobycia z otrzymanych w ten sposób dokumentów istotnych informacji to \textbf{Beautiful Soup}\cite{bs4} - biblioteka dostępna dla języka Python. Pozwala ona na przeszukiwanie plików HTML i XML przy pomocy prostych zapytań. Przykładowo, poniższy fragment kodu znajduje wszystkie elementy HTML będące znacznikiem span i dla których atrybut data-hook ma ustawioną wartość review-body: % ja nie wiem czy to jest do końca poprawne XD
                                            % jest git xD
\begin{lstlisting}
soup.find_all("span", {"data-hook": "review-body"})
\end{lstlisting}

Każdy z otrzymanych w poprzednim kroku plików przeszukano i dla każdego produktu wydobyto treści wszystkich widocznych na stronie recenzji razem z przydzielonymi gwiazdkami. Następnie przystąpiono do oznaczania sentymentów. Przyjęliśmy założenie, że ocena wynosząca 4 lub 5 gwiazdek oznacza wydźwięk pozytywny, ocena 3 -- wydźwięk neutralny, a przyznanie 1 albo 2 gwiazdek wskazuje na wydźwięk negatywny. Tak oznaczone recenzje (treść -- sentyment) zostały zgrupowane według kategorii produktu i zapisane w pliku w formacie CSV.

\subsubsection{Preprocessing}
Preprocessing zostanie wykonany przy użyciu biblioteki \textbf{spaCy}\cite{spacy2}. Jednak zamiast 
wykorzystywać ją bezpośrednio, zostanie ona użyta wewnątrz modułu tokenizatora biblioteki
\textbf{PyTorch}\cite{pytorch}. PyTorch będzie podstawowym narzędziem do utworzenia modelu sieci
neuronowej, więc taka integracja narzędzi znacznie ułatwi konstrukcję systemu.

Dane będą załadowane do klasy dziedziczącej po klasie Dataset z PyTorcha. Klasa ta stanowi
API dla klasy Dataloader, która ułatwia wprowadzanie treningowych, walidacyjnych oraz testowych
danych do sieci.

\subsection{Modele wykrywające wydźwięk}
Jak zostało wspomniane wyżej, model zostanie zbudowany przy pomocy biblioteki PyTorch\cite{pytorch}.
Biblioteka ta pozwala na tworzenie architektur sieci neuronowych od zera przy pomocy
gotowych funkcji implementujących dane rodzaje warstw sieci. Poza narzędziami do tworzenia
modeli, PyTorch dostarcza funkcje służące do optymalizacji, wyliczania wartości funkcji
kosztu, czy regualaryzacji.

Aby stworzyć model z modelem BERT służącym za źródło word embeddingu również pomocny będzie 
PyTorch, a dokładniej jego komponent \textbf{torchtext}. Zawiera wszelkie narzędzia służące
do przygotowania danych będących tekstem w języku naturalnym, w tym także pretrenowane modele
word embeddingu, klasyfikatory oraz modele transofrmatorowe.

Do ewaluacji zostanie wykorzystana biblioteka \textbf{TorchMetrics}\cite{torchmetrics}. Posiada zdefiniowane
funkcje ze wszystkimi powszechnie stosowanymi metrykami. Jej użycie z modelami PyTorch jest
niezwykle proste, ponieważ wykonuje operacje na tensorach będących podstawową jednostką
danych w PyTorch.
